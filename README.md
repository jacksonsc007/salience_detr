Branch: reppoints

The concept of sampling locations of deformable attention share the same spirit with reppoints. Experiments are conducted to validate if the idea of reppoints could be embedded into the deformable attention process of decoder for detrs.

# v1.0
Following <RepPoints>, we group sampling locations to form pseu-boxes on whice box losses are imposed. 

# v1.1
- [x] pay attention to the initialization of box embed
- [x] get rid of extra normalization in the decoder
- [x] disable look forward twice



# v1.1.1
Don't apply explicit supervison on rep-boxes generated by cross-attention. Note that gradients of both rep-points and rep-boxes are detached.

```python
rep_point2 = tmp * (rep_box1[..., 2:][:, :, None, None, None, :]).detach() + rep_point1.detach()
rep_points_2.append(rep_point2)
output_coord = points2box(rep_point2)
```



# TODOs
- [] iterative refinement of reppoints across different decoder layers.  

- [] class supervison on reppoints.

- [] As extra loss is introduced, loss coefficients may need to adjust.

# v1.1.2
Limit the number of reppoints to 8. Reppoints are same for all feature levels.

- [x] Change the output number of box_head for decoder
- [x] box_head output logits now

```python            
rep_point2 = tmp + inverse_sigmoid(rep_point1.detach())
```

- [x] use tanh to modulate sampling offsets in cross attention, as no explict supervision is applied on them.

- [x] The gradients of first group of reppoints, which are generated from cross-attention as sampling locations, are propagated to the second group of repoints. 

```python
            rep_point2 = tmp + inverse_sigmoid(rep_point1)
```

## TODO
change the number of reppoints.